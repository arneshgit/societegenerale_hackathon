{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/output_left.csv')\n",
        "\n",
        "# Fill NaN values with placeholders\n",
        "df.fillna('0.0.0.0', inplace=True)  # For IP addresses\n",
        "df.fillna('00:00:00:00:00:00', inplace=True)  # For MAC addresses\n",
        "\n",
        "# Drop IP, MAC address, and address columns\n",
        "df.drop(columns=['sMACs', 'rMACs', 'sIPs', 'rIPs', 'sAddress', 'rAddress'], inplace=True)\n",
        "\n",
        "# Convert datetime columns to appropriate numeric representations\n",
        "df['startDate'] = pd.to_datetime(df['startDate']).astype(int) // 10**9  # Convert to Unix timestamp\n",
        "\n",
        "# Encode 'protocol' column\n",
        "le = LabelEncoder()\n",
        "df['protocol'] = le.fit_transform(df['protocol'])\n",
        "\n",
        "# Select features and target (assuming 'NST_B_Label' is the target for binary classification)\n",
        "features = df.drop(columns=['IT_B_Label', 'IT_M_Label', 'NST_B_Label', 'NST_M_Label'])\n",
        "target = df['NST_B_Label']  #'NST_B_Label' for binary anomaly detection\n",
        "\n",
        "# Ensure all columns are numeric\n",
        "numeric_features = features.select_dtypes(include=['number'])\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(numeric_features)\n",
        "\n",
        "# Convert back to a DataFrame\n",
        "features_scaled_df = pd.DataFrame(features_scaled, columns=numeric_features.columns)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled_df, target, test_size=0.1, random_state=10)\n",
        "\n",
        "# Display the shapes of the resulting datasets\n",
        "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeJK1KlPrXnZ",
        "outputId": "ea448851-f9d2-4297-d264-9a71055c3f80"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (7699, 15), y_train shape: (7699,)\n",
            "X_test shape: (856, 15), y_test shape: (856,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "'''print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "exx3H0xYvPKP",
        "outputId": "05a24c3b-92b8-484f-cd40-e8517fcd15eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"Classification Report:\")\\nprint(classification_report(y_test, y_pred))\\n\\n# Confusion matrix\\nprint(\"Confusion Matrix:\")\\nprint(confusion_matrix(y_test, y_pred))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(clf, 'trained_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxpS30thxCbM",
        "outputId": "26d98547-624a-4cfa-e6ec-33868e997299"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/output_left.csv')\n",
        "\n",
        "# Fill NaN values with placeholders\n",
        "df.fillna('0.0.0.0', inplace=True)  # For IP addresses\n",
        "df.fillna('00:00:00:00:00:00', inplace=True)  # For MAC addresses\n",
        "\n",
        "# Drop IP, MAC address, and address columns\n",
        "df.drop(columns=['sMACs', 'rMACs', 'sIPs', 'rIPs', 'sAddress', 'rAddress'], inplace=True)\n",
        "\n",
        "# Convert datetime columns to appropriate numeric representations\n",
        "df['startDate'] = pd.to_datetime(df['startDate']).astype(int) // 10**9  # Convert to Unix timestamp\n",
        "\n",
        "# Encode 'protocol' column\n",
        "le = LabelEncoder()\n",
        "df['protocol'] = le.fit_transform(df['protocol'])\n",
        "\n",
        "expected_features = [\n",
        "    'protocol','startDate','start','end','startOffset','endOffset','duration',  'sPackets', 'rPackets', 'sBytesSum', 'rBytesSum',\n",
        "    'sLoad','rLoad','sPayloadSum','rPayloadSum'\n",
        "]\n",
        "ground_truth = df['IT_B_Label']\n",
        "# Ensure df only contains the expected features\n",
        "df = df[expected_features]\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load('/content/trained_model.pkl')\n",
        "\n",
        "# Make predictions on new data\n",
        "predictions = model.predict(df)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(ground_truth, predictions)\n",
        "print(\"Accuracy of the model on new data:\", accuracy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJOcgvo_wJ_d",
        "outputId": "66eca94b-0291-496c-c486-1108bee789a3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on new data: 0.7807130333138516\n"
          ]
        }
      ]
    }
  ]
}